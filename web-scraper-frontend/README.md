# Web Scraper for Visitor Classification - Frontend

This project is the frontend component of a web scraping and visitor classification system built with React, TypeScript, and Redux.

## Features

- URL input for website scraping
- Dynamic question generation based on website content
- User response collection
- Visitor classification based on responses
- Real-time feedback and error handling

## Tech Stack

- React 18
- TypeScript
- Redux Toolkit
- Styled Components
- Axios

## Project Structure
web-scraper-frontend/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ common/
â”‚ â”‚ â”‚ â”œâ”€â”€ ErrorMessage.tsx
â”‚ â”‚ â”‚ â””â”€â”€ LoadingSpinner.tsx
â”‚ â”‚ â””â”€â”€ features/
â”‚ â”‚ â”œâ”€â”€ UrlInput.tsx
â”‚ â”‚ â”œâ”€â”€ QuestionDisplay.tsx
â”‚ â”‚ â””â”€â”€ AnswerSection.tsx
â”‚ â”œâ”€â”€ store/
â”‚ â”‚ â”œâ”€â”€ slices/
â”‚ â”‚ â”‚ â””â”€â”€ scraperSlice.ts
â”‚ â”‚ â””â”€â”€ index.ts
â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â””â”€â”€ api.ts
â”‚ â”œâ”€â”€ styles/
â”‚ â”‚ â””â”€â”€ GlobalStyles.ts
â”‚ â””â”€â”€ App.tsx

## Development Progress

### Completed
- âœ… Frontend project setup with React and TypeScript
- âœ… Redux store configuration
- âœ… Basic component structure
- âœ… API service layer

### In Progress
- ðŸ”„ Backend development with Flask
- ðŸ”„ AWS infrastructure setup
- ðŸ”„ Integration testing

### TODO
- â­• Implement web scraping logic
- â­• Add AWS Comprehend integration
- â­• Enhance UI/UX design
- â­• Add user authentication
- â­• Implement caching mechanism
- â­• Add analytics dashboard
- â­• Write comprehensive tests

## Technical Implementation Details

### Frontend Architecture
The frontend is built with a focus on maintainability and scalability:
- **Component Structure**: Organized into feature-based and common components
- **State Management**: Centralized Redux store with async thunks for API calls
- **Type Safety**: Comprehensive TypeScript implementation
- **Styling**: Modular styled-components with global theming

### API Integration
- RESTful API communication using Axios
- Type-safe API responses
- Error handling and loading states
- Response caching (planned)

## Next Steps

The immediate focus is on developing the backend infrastructure and implementing the core web scraping functionality. This will be followed by AWS service integration and enhanced frontend features.

## License
This project is licensed under the MIT License.